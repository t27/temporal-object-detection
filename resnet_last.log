2020-05-03 02:04:15,694 - root - INFO - Use Cuda.
2020-05-03 02:04:15,694 - root - INFO - Namespace(base_net_lr=None, batch_size=120, cache_path='cache/', checkpoint_folder='models/', datasets='../../ILSVRC', debug_steps=100, feature='resnet18', gamma=0.1, lr=0.003, milestones='80,100', momentum=0.9, num_epochs=5, num_workers=4, pretrained=None, resume=None, scheduler='multi-step', ssd_lr=None, t_max=120, use_cuda=True, validation_epochs=2, weight_decay=0.0005, width_mult=1.0)
2020-05-03 02:04:15,695 - root - INFO - Prepare training datasets.
2020-05-03 02:04:15,894 - root - INFO - using default Imagenet VID classes.
2020-05-03 02:04:29,741 - root - INFO - gt roidb loaded from cache/train_VID_gt_db.pkl
2020-05-03 02:04:29,741 - root - INFO - Stored labels into file models/vid-model-labels.txt.
2020-05-03 02:04:29,741 - root - INFO - Train dataset size: 1086132
2020-05-03 02:04:29,741 - root - INFO - Prepare Validation datasets.
2020-05-03 02:04:29,743 - root - INFO - using default Imagenet VID classes.
2020-05-03 02:04:29,852 - root - INFO - gt roidb loaded from cache/val_VID_gt_db.pkl
2020-05-03 02:04:29,852 - root - INFO - <datasets.vid_dataset_new.ImagenetDataset object at 0x7f4697de6080>
2020-05-03 02:04:29,852 - root - INFO - validation dataset size: 11080
2020-05-03 02:04:29,852 - root - INFO - Build network.
2020-05-03 02:04:30,134 - root - INFO - Initializing weights of SSD
2020-05-03 02:04:31,280 - root - INFO - Learning rate: 0.003, Base net learning rate: 0.003, Extra Layers learning rate: 0.003.
2020-05-03 02:04:31,280 - root - INFO - Start training from epoch 0.
2020-05-03 02:06:41,476 - root - INFO - Epoch: 0, Step: 100, Average Loss: 101.5348, Average Regression Loss 11.5426, Average Classification Loss: 89.9921
2020-05-03 02:08:44,988 - root - INFO - Epoch: 0, Step: 200, Average Loss: 98.7402, Average Regression Loss 4.9203, Average Classification Loss: 93.8199
2020-05-03 02:10:49,841 - root - INFO - Epoch: 0, Step: 300, Average Loss: 86.2786, Average Regression Loss 4.0724, Average Classification Loss: 82.2061
2020-05-03 02:12:54,353 - root - INFO - Epoch: 0, Step: 400, Average Loss: 76.0764, Average Regression Loss 3.7957, Average Classification Loss: 72.2807
2020-05-03 02:14:59,648 - root - INFO - Epoch: 0, Step: 500, Average Loss: 74.6249, Average Regression Loss 4.3030, Average Classification Loss: 70.3218
2020-05-03 02:17:06,781 - root - INFO - Epoch: 0, Step: 600, Average Loss: 71.0285, Average Regression Loss 3.9662, Average Classification Loss: 67.0623
2020-05-03 02:19:10,494 - root - INFO - Epoch: 0, Step: 700, Average Loss: 60.5792, Average Regression Loss 3.9950, Average Classification Loss: 56.5842
2020-05-03 02:21:16,679 - root - INFO - Epoch: 0, Step: 800, Average Loss: 57.3663, Average Regression Loss 4.0296, Average Classification Loss: 53.3366
2020-05-03 02:23:22,284 - root - INFO - Epoch: 0, Step: 900, Average Loss: 51.6305, Average Regression Loss 4.5141, Average Classification Loss: 47.1164
2020-05-03 02:25:28,840 - root - INFO - Epoch: 0, Step: 1000, Average Loss: 52.9203, Average Regression Loss 5.2089, Average Classification Loss: 47.7114
2020-05-03 02:27:33,561 - root - INFO - Epoch: 0, Step: 1100, Average Loss: 60.5011, Average Regression Loss 4.5967, Average Classification Loss: 55.9044
2020-05-03 02:29:42,284 - root - INFO - Epoch: 0, Step: 1200, Average Loss: 62.9127, Average Regression Loss 5.1582, Average Classification Loss: 57.7546
2020-05-03 02:31:47,694 - root - INFO - Epoch: 0, Step: 1300, Average Loss: 69.5300, Average Regression Loss 5.0302, Average Classification Loss: 64.4999
2020-05-03 02:33:53,861 - root - INFO - Epoch: 0, Step: 1400, Average Loss: 78.2779, Average Regression Loss 4.7677, Average Classification Loss: 73.5101
2020-05-03 02:35:54,500 - root - INFO - Epoch: 0, Step: 1500, Average Loss: 82.3631, Average Regression Loss 4.8805, Average Classification Loss: 77.4826
2020-05-03 02:38:00,482 - root - INFO - Epoch: 0, Step: 1600, Average Loss: 88.7977, Average Regression Loss 4.8731, Average Classification Loss: 83.9246
2020-05-03 02:40:04,278 - root - INFO - Epoch: 0, Step: 1700, Average Loss: 86.8679, Average Regression Loss 5.5025, Average Classification Loss: 81.3655
2020-05-03 02:42:09,652 - root - INFO - Epoch: 0, Step: 1800, Average Loss: 95.2749, Average Regression Loss 5.6540, Average Classification Loss: 89.6208
2020-05-03 02:44:20,940 - root - INFO - Epoch: 0, Step: 1900, Average Loss: 94.0033, Average Regression Loss 5.0519, Average Classification Loss: 88.9514
2020-05-03 02:46:27,029 - root - INFO - Epoch: 0, Step: 2000, Average Loss: 86.1616, Average Regression Loss 4.7349, Average Classification Loss: 81.4267
2020-05-03 02:48:37,949 - root - INFO - Epoch: 0, Step: 2100, Average Loss: 89.4924, Average Regression Loss 4.4810, Average Classification Loss: 85.0114
2020-05-03 02:50:47,109 - root - INFO - Epoch: 0, Step: 2200, Average Loss: 89.0344, Average Regression Loss 5.0703, Average Classification Loss: 83.9641
2020-05-03 02:52:55,518 - root - INFO - Epoch: 0, Step: 2300, Average Loss: 85.1472, Average Regression Loss 4.9933, Average Classification Loss: 80.1539
2020-05-03 02:55:00,306 - root - INFO - Epoch: 0, Step: 2400, Average Loss: 88.7233, Average Regression Loss 6.4262, Average Classification Loss: 82.2971
2020-05-03 02:57:02,080 - root - INFO - Epoch: 0, Step: 2500, Average Loss: 90.4311, Average Regression Loss 5.7984, Average Classification Loss: 84.6327
2020-05-03 02:59:09,595 - root - INFO - Epoch: 0, Step: 2600, Average Loss: 95.2631, Average Regression Loss 6.2357, Average Classification Loss: 89.0273
2020-05-03 03:01:14,131 - root - INFO - Epoch: 0, Step: 2700, Average Loss: 85.1721, Average Regression Loss 5.6297, Average Classification Loss: 79.5424
2020-05-03 03:03:19,179 - root - INFO - Epoch: 0, Step: 2800, Average Loss: 98.3860, Average Regression Loss 5.2108, Average Classification Loss: 93.1752
2020-05-03 03:05:22,354 - root - INFO - Epoch: 0, Step: 2900, Average Loss: 98.6117, Average Regression Loss 4.7765, Average Classification Loss: 93.8352
2020-05-03 03:07:28,915 - root - INFO - Epoch: 0, Step: 3000, Average Loss: 93.1285, Average Regression Loss 5.1892, Average Classification Loss: 87.9392
2020-05-03 03:09:34,063 - root - INFO - Epoch: 0, Step: 3100, Average Loss: 80.7142, Average Regression Loss 4.4295, Average Classification Loss: 76.2847
2020-05-03 03:11:38,774 - root - INFO - Epoch: 0, Step: 3200, Average Loss: 81.9757, Average Regression Loss 4.6849, Average Classification Loss: 77.2908
2020-05-03 03:13:44,864 - root - INFO - Epoch: 0, Step: 3300, Average Loss: 84.6533, Average Regression Loss 4.8974, Average Classification Loss: 79.7559
2020-05-03 03:15:49,721 - root - INFO - Epoch: 0, Step: 3400, Average Loss: 86.4203, Average Regression Loss 4.7079, Average Classification Loss: 81.7124
2020-05-03 03:17:58,783 - root - INFO - Epoch: 0, Step: 3500, Average Loss: 81.5613, Average Regression Loss 5.2430, Average Classification Loss: 76.3183
2020-05-03 03:20:01,041 - root - INFO - Epoch: 0, Step: 3600, Average Loss: 86.1380, Average Regression Loss 4.8932, Average Classification Loss: 81.2448
2020-05-03 03:22:03,936 - root - INFO - Epoch: 0, Step: 3700, Average Loss: 84.5535, Average Regression Loss 4.9260, Average Classification Loss: 79.6275
2020-05-03 03:24:12,541 - root - INFO - Epoch: 0, Step: 3800, Average Loss: 83.3512, Average Regression Loss 4.5323, Average Classification Loss: 78.8188
2020-05-03 03:26:16,306 - root - INFO - Epoch: 0, Step: 3900, Average Loss: 88.8111, Average Regression Loss 5.1853, Average Classification Loss: 83.6258
2020-05-03 03:28:20,793 - root - INFO - Epoch: 0, Step: 4000, Average Loss: 90.0459, Average Regression Loss 6.4597, Average Classification Loss: 83.5862
2020-05-03 03:30:22,782 - root - INFO - Epoch: 0, Step: 4100, Average Loss: 92.3238, Average Regression Loss 5.1720, Average Classification Loss: 87.1518
2020-05-03 03:32:25,998 - root - INFO - Epoch: 0, Step: 4200, Average Loss: 84.2133, Average Regression Loss 4.9167, Average Classification Loss: 79.2966
2020-05-03 03:34:30,321 - root - INFO - Epoch: 0, Step: 4300, Average Loss: 90.0657, Average Regression Loss 5.0318, Average Classification Loss: 85.0338
2020-05-03 03:36:36,150 - root - INFO - Epoch: 0, Step: 4400, Average Loss: 97.6214, Average Regression Loss 5.4838, Average Classification Loss: 92.1377
2020-05-03 03:38:44,553 - root - INFO - Epoch: 0, Step: 4500, Average Loss: 96.2437, Average Regression Loss 5.1492, Average Classification Loss: 91.0945
2020-05-03 03:40:51,456 - root - INFO - Epoch: 0, Step: 4600, Average Loss: 82.3033, Average Regression Loss 5.1389, Average Classification Loss: 77.1644
2020-05-03 03:42:57,355 - root - INFO - Epoch: 0, Step: 4700, Average Loss: 91.0965, Average Regression Loss 4.3477, Average Classification Loss: 86.7489
2020-05-03 03:45:03,028 - root - INFO - Epoch: 0, Step: 4800, Average Loss: 101.2286, Average Regression Loss 4.6041, Average Classification Loss: 96.6245
2020-05-03 03:47:08,826 - root - INFO - Epoch: 0, Step: 4900, Average Loss: 90.9835, Average Regression Loss 5.0348, Average Classification Loss: 85.9487
2020-05-03 03:49:11,752 - root - INFO - Epoch: 0, Step: 5000, Average Loss: 88.7849, Average Regression Loss 4.8918, Average Classification Loss: 83.8931
2020-05-03 03:51:17,650 - root - INFO - Epoch: 0, Step: 5100, Average Loss: 96.7182, Average Regression Loss 6.9374, Average Classification Loss: 89.7809
2020-05-03 03:53:25,145 - root - INFO - Epoch: 0, Step: 5200, Average Loss: 99.6679, Average Regression Loss 6.2460, Average Classification Loss: 93.4219
2020-05-03 03:55:32,686 - root - INFO - Epoch: 0, Step: 5300, Average Loss: 87.6176, Average Regression Loss 5.8874, Average Classification Loss: 81.7302
2020-05-03 03:57:40,708 - root - INFO - Epoch: 0, Step: 5400, Average Loss: 83.2994, Average Regression Loss 5.0243, Average Classification Loss: 78.2750
2020-05-03 03:59:48,385 - root - INFO - Epoch: 0, Step: 5500, Average Loss: 96.7821, Average Regression Loss 5.2356, Average Classification Loss: 91.5465
2020-05-03 04:01:52,049 - root - INFO - Epoch: 0, Step: 5600, Average Loss: 95.7328, Average Regression Loss 5.1285, Average Classification Loss: 90.6043
2020-05-03 04:03:56,745 - root - INFO - Epoch: 0, Step: 5700, Average Loss: 93.6868, Average Regression Loss 5.6778, Average Classification Loss: 88.0089
2020-05-03 04:06:03,495 - root - INFO - Epoch: 0, Step: 5800, Average Loss: 103.5617, Average Regression Loss 7.6595, Average Classification Loss: 95.9022
2020-05-03 04:08:08,814 - root - INFO - Epoch: 0, Step: 5900, Average Loss: 91.0239, Average Regression Loss 6.4620, Average Classification Loss: 84.5618
2020-05-03 04:10:13,423 - root - INFO - Epoch: 0, Step: 6000, Average Loss: 94.6279, Average Regression Loss 6.1039, Average Classification Loss: 88.5240
2020-05-03 04:12:21,096 - root - INFO - Epoch: 0, Step: 6100, Average Loss: 108.6539, Average Regression Loss 4.8865, Average Classification Loss: 103.7674
2020-05-03 04:14:26,678 - root - INFO - Epoch: 0, Step: 6200, Average Loss: 110.5207, Average Regression Loss 4.7838, Average Classification Loss: 105.7370
2020-05-03 04:16:32,609 - root - INFO - Epoch: 0, Step: 6300, Average Loss: 94.2271, Average Regression Loss 5.2278, Average Classification Loss: 88.9993
2020-05-03 04:18:42,338 - root - INFO - Epoch: 0, Step: 6400, Average Loss: 95.2941, Average Regression Loss 4.7825, Average Classification Loss: 90.5116
2020-05-03 04:20:46,334 - root - INFO - Epoch: 0, Step: 6500, Average Loss: 90.3275, Average Regression Loss 4.7304, Average Classification Loss: 85.5971
2020-05-03 04:22:55,011 - root - INFO - Epoch: 0, Step: 6600, Average Loss: 87.9276, Average Regression Loss 5.0279, Average Classification Loss: 82.8997
2020-05-03 04:25:04,458 - root - INFO - Epoch: 0, Step: 6700, Average Loss: 90.9669, Average Regression Loss 5.3375, Average Classification Loss: 85.6293
2020-05-03 04:27:08,222 - root - INFO - Epoch: 0, Step: 6800, Average Loss: 104.3912, Average Regression Loss 7.1735, Average Classification Loss: 97.2177
2020-05-03 04:29:18,453 - root - INFO - Epoch: 0, Step: 6900, Average Loss: 100.0676, Average Regression Loss 6.3189, Average Classification Loss: 93.7487
2020-05-03 04:31:24,198 - root - INFO - Epoch: 0, Step: 7000, Average Loss: 104.3744, Average Regression Loss 6.0487, Average Classification Loss: 98.3257
2020-05-03 04:33:28,742 - root - INFO - Epoch: 0, Step: 7100, Average Loss: 96.7385, Average Regression Loss 5.9778, Average Classification Loss: 90.7607
2020-05-03 04:35:33,487 - root - INFO - Epoch: 0, Step: 7200, Average Loss: 87.4466, Average Regression Loss 5.1529, Average Classification Loss: 82.2937
2020-05-03 04:37:35,758 - root - INFO - Epoch: 0, Step: 7300, Average Loss: 97.1593, Average Regression Loss 4.9536, Average Classification Loss: 92.2057
2020-05-03 04:39:42,171 - root - INFO - Epoch: 0, Step: 7400, Average Loss: 83.4766, Average Regression Loss 4.8914, Average Classification Loss: 78.5852
2020-05-03 04:41:48,274 - root - INFO - Epoch: 0, Step: 7500, Average Loss: 85.4175, Average Regression Loss 4.8937, Average Classification Loss: 80.5238
2020-05-03 04:43:59,118 - root - INFO - Epoch: 0, Step: 7600, Average Loss: 83.8939, Average Regression Loss 4.8873, Average Classification Loss: 79.0067
2020-05-03 04:46:03,522 - root - INFO - Epoch: 0, Step: 7700, Average Loss: 89.7688, Average Regression Loss 5.0863, Average Classification Loss: 84.6824
2020-05-03 04:48:11,226 - root - INFO - Epoch: 0, Step: 7800, Average Loss: 89.8776, Average Regression Loss 5.6196, Average Classification Loss: 84.2580
2020-05-03 04:50:18,101 - root - INFO - Epoch: 0, Step: 7900, Average Loss: 86.6729, Average Regression Loss 5.3227, Average Classification Loss: 81.3502
2020-05-03 04:52:26,333 - root - INFO - Epoch: 0, Step: 8000, Average Loss: 95.0244, Average Regression Loss 5.2361, Average Classification Loss: 89.7883
2020-05-03 04:54:30,345 - root - INFO - Epoch: 0, Step: 8100, Average Loss: 92.7689, Average Regression Loss 4.6398, Average Classification Loss: 88.1291
2020-05-03 04:56:40,296 - root - INFO - Epoch: 0, Step: 8200, Average Loss: 96.9575, Average Regression Loss 4.8272, Average Classification Loss: 92.1303
2020-05-03 04:58:49,315 - root - INFO - Epoch: 0, Step: 8300, Average Loss: 90.6024, Average Regression Loss 4.6898, Average Classification Loss: 85.9126
2020-05-03 05:00:52,792 - root - INFO - Epoch: 0, Step: 8400, Average Loss: 90.8606, Average Regression Loss 4.7506, Average Classification Loss: 86.1100
2020-05-03 05:02:59,504 - root - INFO - Epoch: 0, Step: 8500, Average Loss: 88.2508, Average Regression Loss 5.9881, Average Classification Loss: 82.2627
2020-05-03 05:05:10,042 - root - INFO - Epoch: 0, Step: 8600, Average Loss: 89.2741, Average Regression Loss 5.3658, Average Classification Loss: 83.9083
2020-05-03 05:07:17,309 - root - INFO - Epoch: 0, Step: 8700, Average Loss: 84.6317, Average Regression Loss 5.1973, Average Classification Loss: 79.4344
2020-05-03 05:09:23,698 - root - INFO - Epoch: 0, Step: 8800, Average Loss: 97.1513, Average Regression Loss 5.0868, Average Classification Loss: 92.0645
2020-05-03 05:11:29,703 - root - INFO - Epoch: 0, Step: 8900, Average Loss: 89.8387, Average Regression Loss 4.6563, Average Classification Loss: 85.1824
2020-05-03 05:13:35,862 - root - INFO - Epoch: 0, Step: 9000, Average Loss: 97.6307, Average Regression Loss 5.0424, Average Classification Loss: 92.5882
/home/stars/anaconda3/envs/vlrproj/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
2020-05-03 05:15:05,184 - root - INFO - Epoch: 0, Validation Loss: 114.6076, Validation Regression Loss 8.4774, Validation Classification Loss: 106.1302
2020-05-03 05:15:05,293 - root - INFO - Saved model models/basenet/WM-1.0-Epoch-0-Loss-114.60760993342245.pth
2020-05-03 05:17:15,417 - root - INFO - Epoch: 1, Step: 100, Average Loss: 96.5709, Average Regression Loss 5.9256, Average Classification Loss: 90.6453
2020-05-03 05:19:20,750 - root - INFO - Epoch: 1, Step: 200, Average Loss: 95.2680, Average Regression Loss 5.5906, Average Classification Loss: 89.6774
2020-05-03 05:21:28,213 - root - INFO - Epoch: 1, Step: 300, Average Loss: 96.5915, Average Regression Loss 5.1828, Average Classification Loss: 91.4087
2020-05-03 05:23:30,956 - root - INFO - Epoch: 1, Step: 400, Average Loss: 103.3918, Average Regression Loss 4.8598, Average Classification Loss: 98.5320
2020-05-03 05:25:36,684 - root - INFO - Epoch: 1, Step: 500, Average Loss: 104.7954, Average Regression Loss 6.3395, Average Classification Loss: 98.4559
2020-05-03 05:27:43,874 - root - INFO - Epoch: 1, Step: 600, Average Loss: 90.4645, Average Regression Loss 5.6469, Average Classification Loss: 84.8176
2020-05-03 05:29:52,637 - root - INFO - Epoch: 1, Step: 700, Average Loss: 89.3643, Average Regression Loss 5.2981, Average Classification Loss: 84.0662
2020-05-03 05:32:01,783 - root - INFO - Epoch: 1, Step: 800, Average Loss: 94.1706, Average Regression Loss 5.0147, Average Classification Loss: 89.1559
2020-05-03 05:34:07,655 - root - INFO - Epoch: 1, Step: 900, Average Loss: 89.8199, Average Regression Loss 4.9877, Average Classification Loss: 84.8322
2020-05-03 05:36:14,546 - root - INFO - Epoch: 1, Step: 1000, Average Loss: 86.6705, Average Regression Loss 5.0026, Average Classification Loss: 81.6679
2020-05-03 05:38:16,379 - root - INFO - Epoch: 1, Step: 1100, Average Loss: 103.9786, Average Regression Loss 4.6594, Average Classification Loss: 99.3192
2020-05-03 05:40:25,893 - root - INFO - Epoch: 1, Step: 1200, Average Loss: 115.1905, Average Regression Loss 9.0634, Average Classification Loss: 106.1271
2020-05-03 05:42:32,639 - root - INFO - Epoch: 1, Step: 1300, Average Loss: 93.5895, Average Regression Loss 5.5710, Average Classification Loss: 88.0185
2020-05-03 05:44:36,991 - root - INFO - Epoch: 1, Step: 1400, Average Loss: 90.1831, Average Regression Loss 5.1793, Average Classification Loss: 85.0038
2020-05-03 05:46:39,538 - root - INFO - Epoch: 1, Step: 1500, Average Loss: 88.1107, Average Regression Loss 5.0633, Average Classification Loss: 83.0474
2020-05-03 05:48:41,775 - root - INFO - Epoch: 1, Step: 1600, Average Loss: 97.8285, Average Regression Loss 4.8481, Average Classification Loss: 92.9804
2020-05-03 05:50:48,954 - root - INFO - Epoch: 1, Step: 1700, Average Loss: 93.1181, Average Regression Loss 4.6794, Average Classification Loss: 88.4387
2020-05-03 05:52:51,104 - root - INFO - Epoch: 1, Step: 1800, Average Loss: 88.1335, Average Regression Loss 4.7359, Average Classification Loss: 83.3976
2020-05-03 05:54:56,186 - root - INFO - Epoch: 1, Step: 1900, Average Loss: 92.5299, Average Regression Loss 5.0184, Average Classification Loss: 87.5115
2020-05-03 05:56:58,782 - root - INFO - Epoch: 1, Step: 2000, Average Loss: 102.9561, Average Regression Loss 4.8463, Average Classification Loss: 98.1098
2020-05-03 05:59:02,637 - root - INFO - Epoch: 1, Step: 2100, Average Loss: 91.8401, Average Regression Loss 4.8898, Average Classification Loss: 86.9503
2020-05-03 06:01:07,615 - root - INFO - Epoch: 1, Step: 2200, Average Loss: 101.6294, Average Regression Loss 5.4807, Average Classification Loss: 96.1487
2020-05-03 06:03:13,172 - root - INFO - Epoch: 1, Step: 2300, Average Loss: 92.8216, Average Regression Loss 4.7270, Average Classification Loss: 88.0945
2020-05-03 06:05:19,643 - root - INFO - Epoch: 1, Step: 2400, Average Loss: 94.1336, Average Regression Loss 5.0645, Average Classification Loss: 89.0691
2020-05-03 06:07:22,321 - root - INFO - Epoch: 1, Step: 2500, Average Loss: 82.9689, Average Regression Loss 5.0107, Average Classification Loss: 77.9582
2020-05-03 06:09:26,654 - root - INFO - Epoch: 1, Step: 2600, Average Loss: 90.9741, Average Regression Loss 4.8779, Average Classification Loss: 86.0962
2020-05-03 06:11:36,015 - root - INFO - Epoch: 1, Step: 2700, Average Loss: 96.8441, Average Regression Loss 5.1419, Average Classification Loss: 91.7021
2020-05-03 06:13:40,672 - root - INFO - Epoch: 1, Step: 2800, Average Loss: 88.5050, Average Regression Loss 5.0456, Average Classification Loss: 83.4594
2020-05-03 06:15:47,431 - root - INFO - Epoch: 1, Step: 2900, Average Loss: 96.7452, Average Regression Loss 5.0843, Average Classification Loss: 91.6609
2020-05-03 06:17:54,027 - root - INFO - Epoch: 1, Step: 3000, Average Loss: 101.1858, Average Regression Loss 5.0896, Average Classification Loss: 96.0963
2020-05-03 06:19:57,762 - root - INFO - Epoch: 1, Step: 3100, Average Loss: 111.1807, Average Regression Loss 5.0574, Average Classification Loss: 106.1234
2020-05-03 06:22:01,450 - root - INFO - Epoch: 1, Step: 3200, Average Loss: 101.2429, Average Regression Loss 5.0881, Average Classification Loss: 96.1548
2020-05-03 06:24:05,596 - root - INFO - Epoch: 1, Step: 3300, Average Loss: 92.0632, Average Regression Loss 4.8232, Average Classification Loss: 87.2400
2020-05-03 06:26:11,047 - root - INFO - Epoch: 1, Step: 3400, Average Loss: 91.2575, Average Regression Loss 4.8856, Average Classification Loss: 86.3718
2020-05-03 06:28:16,581 - root - INFO - Epoch: 1, Step: 3500, Average Loss: 96.2605, Average Regression Loss 5.1745, Average Classification Loss: 91.0860
2020-05-03 06:30:24,232 - root - INFO - Epoch: 1, Step: 3600, Average Loss: 92.9787, Average Regression Loss 4.9332, Average Classification Loss: 88.0455
2020-05-03 06:32:33,009 - root - INFO - Epoch: 1, Step: 3700, Average Loss: 100.0682, Average Regression Loss 4.7578, Average Classification Loss: 95.3104
2020-05-03 06:34:37,874 - root - INFO - Epoch: 1, Step: 3800, Average Loss: 112.7529, Average Regression Loss 5.0033, Average Classification Loss: 107.7496
2020-05-03 06:36:43,790 - root - INFO - Epoch: 1, Step: 3900, Average Loss: 89.8769, Average Regression Loss 4.8681, Average Classification Loss: 85.0088
2020-05-03 06:38:44,613 - root - INFO - Epoch: 1, Step: 4000, Average Loss: 90.9235, Average Regression Loss 4.8890, Average Classification Loss: 86.0345
2020-05-03 06:40:49,981 - root - INFO - Epoch: 1, Step: 4100, Average Loss: 88.8285, Average Regression Loss 5.3282, Average Classification Loss: 83.5003
2020-05-03 06:42:54,596 - root - INFO - Epoch: 1, Step: 4200, Average Loss: 92.8454, Average Regression Loss 5.0281, Average Classification Loss: 87.8173
2020-05-03 06:45:02,070 - root - INFO - Epoch: 1, Step: 4300, Average Loss: 85.9176, Average Regression Loss 5.1190, Average Classification Loss: 80.7986
2020-05-03 06:47:08,168 - root - INFO - Epoch: 1, Step: 4400, Average Loss: 93.2772, Average Regression Loss 5.0111, Average Classification Loss: 88.2660
2020-05-03 06:49:14,206 - root - INFO - Epoch: 1, Step: 4500, Average Loss: 98.4184, Average Regression Loss 5.2493, Average Classification Loss: 93.1691
2020-05-03 06:51:16,914 - root - INFO - Epoch: 1, Step: 4600, Average Loss: 110.3504, Average Regression Loss 5.8603, Average Classification Loss: 104.4901
2020-05-03 06:53:25,844 - root - INFO - Epoch: 1, Step: 4700, Average Loss: 99.4117, Average Regression Loss 5.0583, Average Classification Loss: 94.3534
2020-05-03 06:55:29,373 - root - INFO - Epoch: 1, Step: 4800, Average Loss: 101.7474, Average Regression Loss 4.9770, Average Classification Loss: 96.7703
2020-05-03 06:57:38,384 - root - INFO - Epoch: 1, Step: 4900, Average Loss: 96.9012, Average Regression Loss 4.8731, Average Classification Loss: 92.0282
2020-05-03 06:59:45,757 - root - INFO - Epoch: 1, Step: 5000, Average Loss: 83.2027, Average Regression Loss 4.4707, Average Classification Loss: 78.7320
2020-05-03 07:01:51,608 - root - INFO - Epoch: 1, Step: 5100, Average Loss: 83.0659, Average Regression Loss 4.8545, Average Classification Loss: 78.2115
2020-05-03 07:03:58,367 - root - INFO - Epoch: 1, Step: 5200, Average Loss: 87.1997, Average Regression Loss 5.0796, Average Classification Loss: 82.1201
2020-05-03 07:06:00,994 - root - INFO - Epoch: 1, Step: 5300, Average Loss: 88.2108, Average Regression Loss 4.8911, Average Classification Loss: 83.3197
2020-05-03 07:08:07,001 - root - INFO - Epoch: 1, Step: 5400, Average Loss: 93.2616, Average Regression Loss 4.8173, Average Classification Loss: 88.4444
2020-05-03 07:10:09,788 - root - INFO - Epoch: 1, Step: 5500, Average Loss: 88.6551, Average Regression Loss 4.6716, Average Classification Loss: 83.9835
2020-05-03 07:12:16,916 - root - INFO - Epoch: 1, Step: 5600, Average Loss: 97.8075, Average Regression Loss 4.8807, Average Classification Loss: 92.9268
2020-05-03 07:14:22,322 - root - INFO - Epoch: 1, Step: 5700, Average Loss: 96.2339, Average Regression Loss 5.0677, Average Classification Loss: 91.1662
2020-05-03 07:16:25,154 - root - INFO - Epoch: 1, Step: 5800, Average Loss: 98.2842, Average Regression Loss 5.1525, Average Classification Loss: 93.1317
2020-05-03 07:18:32,952 - root - INFO - Epoch: 1, Step: 5900, Average Loss: 94.1209, Average Regression Loss 4.9901, Average Classification Loss: 89.1307
2020-05-03 07:20:38,803 - root - INFO - Epoch: 1, Step: 6000, Average Loss: 95.9115, Average Regression Loss 4.8416, Average Classification Loss: 91.0699
2020-05-03 07:22:42,912 - root - INFO - Epoch: 1, Step: 6100, Average Loss: 101.0198, Average Regression Loss 5.0082, Average Classification Loss: 96.0117
2020-05-03 07:24:50,035 - root - INFO - Epoch: 1, Step: 6200, Average Loss: 94.5851, Average Regression Loss 4.9278, Average Classification Loss: 89.6573
2020-05-03 07:26:54,398 - root - INFO - Epoch: 1, Step: 6300, Average Loss: 89.4506, Average Regression Loss 4.8353, Average Classification Loss: 84.6153
2020-05-03 07:29:01,644 - root - INFO - Epoch: 1, Step: 6400, Average Loss: 94.0176, Average Regression Loss 4.8322, Average Classification Loss: 89.1854
2020-05-03 07:31:06,926 - root - INFO - Epoch: 1, Step: 6500, Average Loss: 96.4907, Average Regression Loss 4.6076, Average Classification Loss: 91.8830
2020-05-03 07:33:12,320 - root - INFO - Epoch: 1, Step: 6600, Average Loss: 92.7226, Average Regression Loss 4.8801, Average Classification Loss: 87.8425
2020-05-03 07:35:22,959 - root - INFO - Epoch: 1, Step: 6700, Average Loss: 87.1169, Average Regression Loss 4.9584, Average Classification Loss: 82.1584
2020-05-03 07:37:29,899 - root - INFO - Epoch: 1, Step: 6800, Average Loss: 94.6366, Average Regression Loss 4.6147, Average Classification Loss: 90.0219
2020-05-03 07:39:36,499 - root - INFO - Epoch: 1, Step: 6900, Average Loss: 94.5094, Average Regression Loss 4.8570, Average Classification Loss: 89.6524
2020-05-03 07:41:42,830 - root - INFO - Epoch: 1, Step: 7000, Average Loss: 101.3261, Average Regression Loss 4.7650, Average Classification Loss: 96.5610
2020-05-03 07:43:50,425 - root - INFO - Epoch: 1, Step: 7100, Average Loss: 107.6147, Average Regression Loss 5.0718, Average Classification Loss: 102.5430
2020-05-03 07:45:55,351 - root - INFO - Epoch: 1, Step: 7200, Average Loss: 93.6317, Average Regression Loss 4.7740, Average Classification Loss: 88.8577
2020-05-03 07:48:01,416 - root - INFO - Epoch: 1, Step: 7300, Average Loss: 91.0028, Average Regression Loss 4.5643, Average Classification Loss: 86.4385
2020-05-03 07:50:06,621 - root - INFO - Epoch: 1, Step: 7400, Average Loss: 82.2194, Average Regression Loss 4.8696, Average Classification Loss: 77.3498
2020-05-03 07:52:11,038 - root - INFO - Epoch: 1, Step: 7500, Average Loss: 80.8514, Average Regression Loss 5.1217, Average Classification Loss: 75.7298
2020-05-03 07:54:22,642 - root - INFO - Epoch: 1, Step: 7600, Average Loss: 98.2098, Average Regression Loss 6.1500, Average Classification Loss: 92.0598
2020-05-03 07:56:29,541 - root - INFO - Epoch: 1, Step: 7700, Average Loss: 95.8854, Average Regression Loss 5.3839, Average Classification Loss: 90.5016
2020-05-03 07:58:35,176 - root - INFO - Epoch: 1, Step: 7800, Average Loss: 88.7747, Average Regression Loss 4.5288, Average Classification Loss: 84.2459
2020-05-03 08:00:43,792 - root - INFO - Epoch: 1, Step: 7900, Average Loss: 82.8086, Average Regression Loss 4.5954, Average Classification Loss: 78.2132
2020-05-03 08:02:48,283 - root - INFO - Epoch: 1, Step: 8000, Average Loss: 82.0498, Average Regression Loss 4.8435, Average Classification Loss: 77.2062
2020-05-03 08:04:53,477 - root - INFO - Epoch: 1, Step: 8100, Average Loss: 83.1563, Average Regression Loss 4.7473, Average Classification Loss: 78.4089
2020-05-03 08:07:01,682 - root - INFO - Epoch: 1, Step: 8200, Average Loss: 92.3749, Average Regression Loss 8.2646, Average Classification Loss: 84.1103
2020-05-03 08:09:11,793 - root - INFO - Epoch: 1, Step: 8300, Average Loss: 82.6632, Average Regression Loss 8.1705, Average Classification Loss: 74.4927
2020-05-03 08:11:12,475 - root - INFO - Epoch: 1, Step: 8400, Average Loss: 79.5572, Average Regression Loss 5.5501, Average Classification Loss: 74.0072
2020-05-03 08:13:16,644 - root - INFO - Epoch: 1, Step: 8500, Average Loss: 88.6208, Average Regression Loss 5.0547, Average Classification Loss: 83.5662
2020-05-03 08:15:24,768 - root - INFO - Epoch: 1, Step: 8600, Average Loss: 83.3208, Average Regression Loss 5.1019, Average Classification Loss: 78.2190
2020-05-03 08:17:30,134 - root - INFO - Epoch: 1, Step: 8700, Average Loss: 89.7827, Average Regression Loss 5.1343, Average Classification Loss: 84.6484
2020-05-03 08:19:39,593 - root - INFO - Epoch: 1, Step: 8800, Average Loss: 98.9015, Average Regression Loss 5.9750, Average Classification Loss: 92.9265
2020-05-03 08:21:46,283 - root - INFO - Epoch: 1, Step: 8900, Average Loss: 96.4560, Average Regression Loss 7.7578, Average Classification Loss: 88.6982
2020-05-03 08:23:54,990 - root - INFO - Epoch: 1, Step: 9000, Average Loss: 88.1438, Average Regression Loss 4.9692, Average Classification Loss: 83.1746
2020-05-03 08:27:08,632 - root - INFO - Epoch: 2, Step: 100, Average Loss: 85.6171, Average Regression Loss 5.3477, Average Classification Loss: 80.2694
2020-05-03 08:29:13,368 - root - INFO - Epoch: 2, Step: 200, Average Loss: 82.4056, Average Regression Loss 5.3052, Average Classification Loss: 77.1004
2020-05-03 08:31:17,585 - root - INFO - Epoch: 2, Step: 300, Average Loss: 88.6871, Average Regression Loss 5.3336, Average Classification Loss: 83.3535
2020-05-03 08:33:21,485 - root - INFO - Epoch: 2, Step: 400, Average Loss: 89.7767, Average Regression Loss 4.8181, Average Classification Loss: 84.9586
2020-05-03 08:35:24,676 - root - INFO - Epoch: 2, Step: 500, Average Loss: 93.6171, Average Regression Loss 5.3796, Average Classification Loss: 88.2375
2020-05-03 08:37:30,005 - root - INFO - Epoch: 2, Step: 600, Average Loss: 92.5472, Average Regression Loss 4.9185, Average Classification Loss: 87.6287
2020-05-03 08:39:36,166 - root - INFO - Epoch: 2, Step: 700, Average Loss: 92.9727, Average Regression Loss 4.7664, Average Classification Loss: 88.2063
2020-05-03 08:41:41,569 - root - INFO - Epoch: 2, Step: 800, Average Loss: 91.7471, Average Regression Loss 5.2488, Average Classification Loss: 86.4983
2020-05-03 08:43:49,541 - root - INFO - Epoch: 2, Step: 900, Average Loss: 87.8683, Average Regression Loss 4.6735, Average Classification Loss: 83.1949
2020-05-03 08:45:59,881 - root - INFO - Epoch: 2, Step: 1000, Average Loss: 89.0591, Average Regression Loss 4.5704, Average Classification Loss: 84.4887
2020-05-03 08:48:02,776 - root - INFO - Epoch: 2, Step: 1100, Average Loss: 94.0173, Average Regression Loss 6.3749, Average Classification Loss: 87.6423
2020-05-03 08:50:10,086 - root - INFO - Epoch: 2, Step: 1200, Average Loss: 96.5534, Average Regression Loss 5.2640, Average Classification Loss: 91.2894
2020-05-03 08:52:15,956 - root - INFO - Epoch: 2, Step: 1300, Average Loss: 100.7031, Average Regression Loss 4.7514, Average Classification Loss: 95.9517
2020-05-03 08:54:21,879 - root - INFO - Epoch: 2, Step: 1400, Average Loss: 93.9791, Average Regression Loss 6.0875, Average Classification Loss: 87.8916
2020-05-03 08:56:25,662 - root - INFO - Epoch: 2, Step: 1500, Average Loss: 83.9241, Average Regression Loss 4.9907, Average Classification Loss: 78.9334
2020-05-03 08:58:33,342 - root - INFO - Epoch: 2, Step: 1600, Average Loss: 91.9267, Average Regression Loss 4.7313, Average Classification Loss: 87.1954
2020-05-03 09:00:41,334 - root - INFO - Epoch: 2, Step: 1700, Average Loss: 96.8547, Average Regression Loss 5.0433, Average Classification Loss: 91.8114
2020-05-03 09:02:41,865 - root - INFO - Epoch: 2, Step: 1800, Average Loss: 97.9234, Average Regression Loss 4.8435, Average Classification Loss: 93.0799
2020-05-03 09:04:45,451 - root - INFO - Epoch: 2, Step: 1900, Average Loss: 99.1838, Average Regression Loss 4.6832, Average Classification Loss: 94.5006
2020-05-03 09:06:52,811 - root - INFO - Epoch: 2, Step: 2000, Average Loss: 95.9550, Average Regression Loss 4.8343, Average Classification Loss: 91.1207
2020-05-03 09:08:57,001 - root - INFO - Epoch: 2, Step: 2100, Average Loss: 89.2076, Average Regression Loss 4.7801, Average Classification Loss: 84.4275
2020-05-03 09:11:06,246 - root - INFO - Epoch: 2, Step: 2200, Average Loss: 102.4941, Average Regression Loss 5.5097, Average Classification Loss: 96.9845
2020-05-03 09:13:12,298 - root - INFO - Epoch: 2, Step: 2300, Average Loss: 101.5117, Average Regression Loss 5.1341, Average Classification Loss: 96.3777
2020-05-03 09:15:16,945 - root - INFO - Epoch: 2, Step: 2400, Average Loss: 92.8500, Average Regression Loss 4.5510, Average Classification Loss: 88.2990
2020-05-03 09:17:21,955 - root - INFO - Epoch: 2, Step: 2500, Average Loss: 90.0696, Average Regression Loss 4.9192, Average Classification Loss: 85.1504
2020-05-03 09:19:29,454 - root - INFO - Epoch: 2, Step: 2600, Average Loss: 96.4576, Average Regression Loss 4.8118, Average Classification Loss: 91.6458
2020-05-03 09:21:35,817 - root - INFO - Epoch: 2, Step: 2700, Average Loss: 102.6590, Average Regression Loss 5.3862, Average Classification Loss: 97.2728
2020-05-03 09:23:42,964 - root - INFO - Epoch: 2, Step: 2800, Average Loss: 98.9051, Average Regression Loss 4.9472, Average Classification Loss: 93.9580
2020-05-03 09:25:46,625 - root - INFO - Epoch: 2, Step: 2900, Average Loss: 91.1322, Average Regression Loss 4.8286, Average Classification Loss: 86.3035
2020-05-03 09:27:52,098 - root - INFO - Epoch: 2, Step: 3000, Average Loss: 106.2033, Average Regression Loss 5.1018, Average Classification Loss: 101.1016
2020-05-03 09:29:59,434 - root - INFO - Epoch: 2, Step: 3100, Average Loss: 105.6782, Average Regression Loss 4.7313, Average Classification Loss: 100.9470
2020-05-03 09:32:01,367 - root - INFO - Epoch: 2, Step: 3200, Average Loss: 96.4574, Average Regression Loss 4.9260, Average Classification Loss: 91.5315
2020-05-03 09:34:09,499 - root - INFO - Epoch: 2, Step: 3300, Average Loss: 90.6303, Average Regression Loss 5.1457, Average Classification Loss: 85.4846
2020-05-03 09:36:18,667 - root - INFO - Epoch: 2, Step: 3400, Average Loss: 101.3867, Average Regression Loss 6.5864, Average Classification Loss: 94.8003
2020-05-03 09:38:25,482 - root - INFO - Epoch: 2, Step: 3500, Average Loss: 104.4556, Average Regression Loss 9.0048, Average Classification Loss: 95.4507
2020-05-03 09:40:32,697 - root - INFO - Epoch: 2, Step: 3600, Average Loss: 92.6813, Average Regression Loss 5.3957, Average Classification Loss: 87.2856
2020-05-03 09:42:39,514 - root - INFO - Epoch: 2, Step: 3700, Average Loss: 97.5198, Average Regression Loss 5.3797, Average Classification Loss: 92.1401
2020-05-03 09:44:48,843 - root - INFO - Epoch: 2, Step: 3800, Average Loss: 103.8677, Average Regression Loss 5.9212, Average Classification Loss: 97.9464
2020-05-03 09:46:51,886 - root - INFO - Epoch: 2, Step: 3900, Average Loss: 100.5052, Average Regression Loss 5.3695, Average Classification Loss: 95.1357
2020-05-03 09:48:50,342 - root - INFO - Epoch: 2, Step: 4000, Average Loss: 99.0585, Average Regression Loss 5.3285, Average Classification Loss: 93.7300
2020-05-03 09:50:54,164 - root - INFO - Epoch: 2, Step: 4100, Average Loss: 93.4661, Average Regression Loss 5.5423, Average Classification Loss: 87.9238
2020-05-03 09:52:58,677 - root - INFO - Epoch: 2, Step: 4200, Average Loss: 87.2077, Average Regression Loss 5.2617, Average Classification Loss: 81.9460
2020-05-03 09:55:05,357 - root - INFO - Epoch: 2, Step: 4300, Average Loss: 84.8080, Average Regression Loss 4.8692, Average Classification Loss: 79.9388
2020-05-03 09:57:07,053 - root - INFO - Epoch: 2, Step: 4400, Average Loss: 81.2557, Average Regression Loss 4.6528, Average Classification Loss: 76.6029
2020-05-03 09:59:12,050 - root - INFO - Epoch: 2, Step: 4500, Average Loss: 75.1124, Average Regression Loss 4.4378, Average Classification Loss: 70.6745
2020-05-03 10:01:16,589 - root - INFO - Epoch: 2, Step: 4600, Average Loss: 83.5019, Average Regression Loss 4.5904, Average Classification Loss: 78.9115
2020-05-03 10:03:21,556 - root - INFO - Epoch: 2, Step: 4700, Average Loss: 82.7796, Average Regression Loss 5.0113, Average Classification Loss: 77.7684
2020-05-03 10:05:26,634 - root - INFO - Epoch: 2, Step: 4800, Average Loss: 87.7505, Average Regression Loss 5.1242, Average Classification Loss: 82.6264
2020-05-03 10:07:28,292 - root - INFO - Epoch: 2, Step: 4900, Average Loss: 90.2160, Average Regression Loss 4.8696, Average Classification Loss: 85.3464
2020-05-03 10:09:32,875 - root - INFO - Epoch: 2, Step: 5000, Average Loss: 87.2391, Average Regression Loss 4.4206, Average Classification Loss: 82.8185
2020-05-03 10:11:38,932 - root - INFO - Epoch: 2, Step: 5100, Average Loss: 96.1148, Average Regression Loss 6.1776, Average Classification Loss: 89.9372
2020-05-03 10:13:44,271 - root - INFO - Epoch: 2, Step: 5200, Average Loss: 101.9471, Average Regression Loss 5.8854, Average Classification Loss: 96.0618
2020-05-03 10:15:48,284 - root - INFO - Epoch: 2, Step: 5300, Average Loss: 88.4809, Average Regression Loss 5.0218, Average Classification Loss: 83.4590
2020-05-03 10:17:53,863 - root - INFO - Epoch: 2, Step: 5400, Average Loss: 83.2248, Average Regression Loss 5.2248, Average Classification Loss: 77.9999
2020-05-03 10:19:59,378 - root - INFO - Epoch: 2, Step: 5500, Average Loss: 79.4833, Average Regression Loss 4.6646, Average Classification Loss: 74.8187
2020-05-03 10:22:01,970 - root - INFO - Epoch: 2, Step: 5600, Average Loss: 85.3901, Average Regression Loss 4.7610, Average Classification Loss: 80.6291
2020-05-03 10:24:05,731 - root - INFO - Epoch: 2, Step: 5700, Average Loss: 98.3132, Average Regression Loss 5.2283, Average Classification Loss: 93.0849
2020-05-03 10:26:08,125 - root - INFO - Epoch: 2, Step: 5800, Average Loss: 85.5933, Average Regression Loss 5.0570, Average Classification Loss: 80.5363
2020-05-03 10:28:14,379 - root - INFO - Epoch: 2, Step: 5900, Average Loss: 88.2463, Average Regression Loss 4.9130, Average Classification Loss: 83.3334
2020-05-03 10:30:20,549 - root - INFO - Epoch: 2, Step: 6000, Average Loss: 95.0458, Average Regression Loss 5.1120, Average Classification Loss: 89.9338
2020-05-03 10:32:24,519 - root - INFO - Epoch: 2, Step: 6100, Average Loss: 96.9057, Average Regression Loss 5.3319, Average Classification Loss: 91.5738
2020-05-03 10:34:31,231 - root - INFO - Epoch: 2, Step: 6200, Average Loss: 89.1186, Average Regression Loss 5.3391, Average Classification Loss: 83.7796
2020-05-03 10:36:39,227 - root - INFO - Epoch: 2, Step: 6300, Average Loss: 84.6644, Average Regression Loss 5.2848, Average Classification Loss: 79.3796
2020-05-03 10:38:45,855 - root - INFO - Epoch: 2, Step: 6400, Average Loss: 85.3377, Average Regression Loss 4.9823, Average Classification Loss: 80.3554
2020-05-03 10:40:50,446 - root - INFO - Epoch: 2, Step: 6500, Average Loss: 89.6322, Average Regression Loss 4.9320, Average Classification Loss: 84.7003
2020-05-03 10:42:59,864 - root - INFO - Epoch: 2, Step: 6600, Average Loss: 92.5842, Average Regression Loss 4.6960, Average Classification Loss: 87.8882
2020-05-03 10:45:07,562 - root - INFO - Epoch: 2, Step: 6700, Average Loss: 80.7559, Average Regression Loss 4.7485, Average Classification Loss: 76.0074
2020-05-03 10:47:13,821 - root - INFO - Epoch: 2, Step: 6800, Average Loss: 76.5940, Average Regression Loss 4.9366, Average Classification Loss: 71.6573
2020-05-03 10:49:21,781 - root - INFO - Epoch: 2, Step: 6900, Average Loss: 96.7415, Average Regression Loss 7.5613, Average Classification Loss: 89.1801
2020-05-03 10:51:25,057 - root - INFO - Epoch: 2, Step: 7000, Average Loss: 96.4914, Average Regression Loss 9.6050, Average Classification Loss: 86.8864
2020-05-03 10:53:32,890 - root - INFO - Epoch: 2, Step: 7100, Average Loss: 83.7892, Average Regression Loss 7.4979, Average Classification Loss: 76.2913
2020-05-03 10:55:37,709 - root - INFO - Epoch: 2, Step: 7200, Average Loss: 76.2475, Average Regression Loss 7.0598, Average Classification Loss: 69.1877
2020-05-03 10:57:43,646 - root - INFO - Epoch: 2, Step: 7300, Average Loss: 77.1036, Average Regression Loss 5.9095, Average Classification Loss: 71.1941
2020-05-03 10:59:47,534 - root - INFO - Epoch: 2, Step: 7400, Average Loss: 79.6563, Average Regression Loss 5.5544, Average Classification Loss: 74.1019
2020-05-03 11:01:53,784 - root - INFO - Epoch: 2, Step: 7500, Average Loss: 85.6086, Average Regression Loss 5.4075, Average Classification Loss: 80.2011
2020-05-03 11:04:00,610 - root - INFO - Epoch: 2, Step: 7600, Average Loss: 85.6955, Average Regression Loss 5.0019, Average Classification Loss: 80.6936
2020-05-03 11:06:02,584 - root - INFO - Epoch: 2, Step: 7700, Average Loss: 86.0615, Average Regression Loss 5.1040, Average Classification Loss: 80.9575
2020-05-03 11:08:09,286 - root - INFO - Epoch: 2, Step: 7800, Average Loss: 86.5160, Average Regression Loss 5.9787, Average Classification Loss: 80.5373
2020-05-03 11:10:16,419 - root - INFO - Epoch: 2, Step: 7900, Average Loss: 89.4046, Average Regression Loss 5.5988, Average Classification Loss: 83.8057
2020-05-03 11:12:22,758 - root - INFO - Epoch: 2, Step: 8000, Average Loss: 91.6293, Average Regression Loss 5.3367, Average Classification Loss: 86.2926
2020-05-03 11:14:29,516 - root - INFO - Epoch: 2, Step: 8100, Average Loss: 87.2757, Average Regression Loss 5.5342, Average Classification Loss: 81.7416
2020-05-03 11:16:37,211 - root - INFO - Epoch: 2, Step: 8200, Average Loss: 85.2034, Average Regression Loss 5.1256, Average Classification Loss: 80.0778
2020-05-03 11:18:45,496 - root - INFO - Epoch: 2, Step: 8300, Average Loss: 94.4544, Average Regression Loss 5.1837, Average Classification Loss: 89.2707
2020-05-03 11:20:45,027 - root - INFO - Epoch: 2, Step: 8400, Average Loss: 91.6895, Average Regression Loss 5.3079, Average Classification Loss: 86.3815
2020-05-03 11:22:50,368 - root - INFO - Epoch: 2, Step: 8500, Average Loss: 98.2133, Average Regression Loss 6.4019, Average Classification Loss: 91.8114
2020-05-03 11:24:57,432 - root - INFO - Epoch: 2, Step: 8600, Average Loss: 90.1740, Average Regression Loss 6.0349, Average Classification Loss: 84.1392
2020-05-03 11:27:02,851 - root - INFO - Epoch: 2, Step: 8700, Average Loss: 98.9602, Average Regression Loss 5.7766, Average Classification Loss: 93.1835
2020-05-03 11:29:11,867 - root - INFO - Epoch: 2, Step: 8800, Average Loss: 90.3135, Average Regression Loss 5.4450, Average Classification Loss: 84.8685
2020-05-03 11:31:16,907 - root - INFO - Epoch: 2, Step: 8900, Average Loss: 94.3009, Average Regression Loss 6.0595, Average Classification Loss: 88.2414
2020-05-03 11:33:25,057 - root - INFO - Epoch: 2, Step: 9000, Average Loss: 102.7427, Average Regression Loss 6.1863, Average Classification Loss: 96.5564
2020-05-03 11:34:56,945 - root - INFO - Epoch: 2, Validation Loss: 94.1198, Validation Regression Loss 6.8840, Validation Classification Loss: 87.2358
2020-05-03 11:34:57,048 - root - INFO - Saved model models/basenet/WM-1.0-Epoch-2-Loss-94.11976846059163.pth
2020-05-03 11:37:09,579 - root - INFO - Epoch: 3, Step: 100, Average Loss: 89.2461, Average Regression Loss 5.3197, Average Classification Loss: 83.9264
2020-05-03 11:39:14,805 - root - INFO - Epoch: 3, Step: 200, Average Loss: 91.9674, Average Regression Loss 5.2667, Average Classification Loss: 86.7007
2020-05-03 11:41:21,670 - root - INFO - Epoch: 3, Step: 300, Average Loss: 100.7535, Average Regression Loss 5.2203, Average Classification Loss: 95.5331
2020-05-03 11:43:29,361 - root - INFO - Epoch: 3, Step: 400, Average Loss: 88.2164, Average Regression Loss 5.3613, Average Classification Loss: 82.8550
2020-05-03 11:45:36,989 - root - INFO - Epoch: 3, Step: 500, Average Loss: 87.8213, Average Regression Loss 7.5207, Average Classification Loss: 80.3006
2020-05-03 11:47:41,772 - root - INFO - Epoch: 3, Step: 600, Average Loss: 92.4901, Average Regression Loss 6.2967, Average Classification Loss: 86.1934
2020-05-03 11:49:49,056 - root - INFO - Epoch: 3, Step: 700, Average Loss: 102.0701, Average Regression Loss 5.3645, Average Classification Loss: 96.7056
2020-05-03 11:51:54,908 - root - INFO - Epoch: 3, Step: 800, Average Loss: 96.4063, Average Regression Loss 5.1712, Average Classification Loss: 91.2351
2020-05-03 11:53:58,119 - root - INFO - Epoch: 3, Step: 900, Average Loss: 91.7566, Average Regression Loss 5.4681, Average Classification Loss: 86.2886
2020-05-03 11:56:01,820 - root - INFO - Epoch: 3, Step: 1000, Average Loss: 103.2266, Average Regression Loss 5.5098, Average Classification Loss: 97.7168
2020-05-03 11:58:06,211 - root - INFO - Epoch: 3, Step: 1100, Average Loss: 88.8321, Average Regression Loss 5.3190, Average Classification Loss: 83.5131
2020-05-03 12:00:13,079 - root - INFO - Epoch: 3, Step: 1200, Average Loss: 102.3049, Average Regression Loss 5.7819, Average Classification Loss: 96.5229
2020-05-03 12:02:17,633 - root - INFO - Epoch: 3, Step: 1300, Average Loss: 103.4351, Average Regression Loss 5.0275, Average Classification Loss: 98.4077
2020-05-03 12:04:21,595 - root - INFO - Epoch: 3, Step: 1400, Average Loss: 94.9549, Average Regression Loss 4.7851, Average Classification Loss: 90.1698
2020-05-03 12:06:29,221 - root - INFO - Epoch: 3, Step: 1500, Average Loss: 93.4260, Average Regression Loss 5.4537, Average Classification Loss: 87.9723
2020-05-03 12:08:33,914 - root - INFO - Epoch: 3, Step: 1600, Average Loss: 87.1835, Average Regression Loss 5.1256, Average Classification Loss: 82.0579
2020-05-03 12:10:39,833 - root - INFO - Epoch: 3, Step: 1700, Average Loss: 92.7870, Average Regression Loss 5.3013, Average Classification Loss: 87.4857
2020-05-03 12:12:42,512 - root - INFO - Epoch: 3, Step: 1800, Average Loss: 98.6207, Average Regression Loss 5.2151, Average Classification Loss: 93.4056
2020-05-03 12:14:48,785 - root - INFO - Epoch: 3, Step: 1900, Average Loss: 96.6146, Average Regression Loss 5.1865, Average Classification Loss: 91.4280
2020-05-03 12:16:53,831 - root - INFO - Epoch: 3, Step: 2000, Average Loss: 92.9286, Average Regression Loss 5.4576, Average Classification Loss: 87.4710
2020-05-03 12:19:00,429 - root - INFO - Epoch: 3, Step: 2100, Average Loss: 98.2312, Average Regression Loss 5.1825, Average Classification Loss: 93.0487
2020-05-03 12:21:06,557 - root - INFO - Epoch: 3, Step: 2200, Average Loss: 97.3673, Average Regression Loss 6.3810, Average Classification Loss: 90.9863
2020-05-03 12:23:13,058 - root - INFO - Epoch: 3, Step: 2300, Average Loss: 92.4810, Average Regression Loss 5.3535, Average Classification Loss: 87.1275
2020-05-03 12:25:22,250 - root - INFO - Epoch: 3, Step: 2400, Average Loss: 98.1008, Average Regression Loss 4.9138, Average Classification Loss: 93.1870
2020-05-03 12:27:29,242 - root - INFO - Epoch: 3, Step: 2500, Average Loss: 96.4671, Average Regression Loss 5.2425, Average Classification Loss: 91.2246
2020-05-03 12:29:30,634 - root - INFO - Epoch: 3, Step: 2600, Average Loss: 103.9175, Average Regression Loss 5.1902, Average Classification Loss: 98.7273
2020-05-03 12:31:36,825 - root - INFO - Epoch: 3, Step: 2700, Average Loss: 94.5639, Average Regression Loss 5.8500, Average Classification Loss: 88.7139
2020-05-03 12:33:40,321 - root - INFO - Epoch: 3, Step: 2800, Average Loss: 105.3891, Average Regression Loss 6.3119, Average Classification Loss: 99.0772
2020-05-03 12:35:48,267 - root - INFO - Epoch: 3, Step: 2900, Average Loss: 100.1056, Average Regression Loss 5.5118, Average Classification Loss: 94.5939
2020-05-03 12:37:49,119 - root - INFO - Epoch: 3, Step: 3000, Average Loss: 82.9603, Average Regression Loss 4.8808, Average Classification Loss: 78.0795
2020-05-03 12:39:59,081 - root - INFO - Epoch: 3, Step: 3100, Average Loss: 94.3188, Average Regression Loss 6.2533, Average Classification Loss: 88.0656
2020-05-03 12:42:04,144 - root - INFO - Epoch: 3, Step: 3200, Average Loss: 87.6103, Average Regression Loss 5.8646, Average Classification Loss: 81.7457
2020-05-03 12:44:08,906 - root - INFO - Epoch: 3, Step: 3300, Average Loss: 96.1366, Average Regression Loss 6.1988, Average Classification Loss: 89.9378
2020-05-03 12:46:13,288 - root - INFO - Epoch: 3, Step: 3400, Average Loss: 100.9206, Average Regression Loss 6.4171, Average Classification Loss: 94.5035
2020-05-03 12:48:21,421 - root - INFO - Epoch: 3, Step: 3500, Average Loss: 99.6808, Average Regression Loss 5.9711, Average Classification Loss: 93.7097
2020-05-03 12:50:27,225 - root - INFO - Epoch: 3, Step: 3600, Average Loss: 99.9365, Average Regression Loss 5.5680, Average Classification Loss: 94.3685
2020-05-03 12:52:31,473 - root - INFO - Epoch: 3, Step: 3700, Average Loss: 104.0028, Average Regression Loss 5.9279, Average Classification Loss: 98.0749
2020-05-03 12:54:37,754 - root - INFO - Epoch: 3, Step: 3800, Average Loss: 100.0439, Average Regression Loss 6.1640, Average Classification Loss: 93.8799
2020-05-03 12:56:39,874 - root - INFO - Epoch: 3, Step: 3900, Average Loss: 99.9924, Average Regression Loss 5.3892, Average Classification Loss: 94.6032
2020-05-03 12:58:46,876 - root - INFO - Epoch: 3, Step: 4000, Average Loss: 91.6914, Average Regression Loss 5.0601, Average Classification Loss: 86.6313
2020-05-03 13:00:51,428 - root - INFO - Epoch: 3, Step: 4100, Average Loss: 92.1117, Average Regression Loss 4.8262, Average Classification Loss: 87.2855
2020-05-03 13:02:54,366 - root - INFO - Epoch: 3, Step: 4200, Average Loss: 93.7983, Average Regression Loss 5.0538, Average Classification Loss: 88.7445
2020-05-03 13:05:02,461 - root - INFO - Epoch: 3, Step: 4300, Average Loss: 82.7542, Average Regression Loss 4.6593, Average Classification Loss: 78.0949
2020-05-03 13:07:07,020 - root - INFO - Epoch: 3, Step: 4400, Average Loss: 86.5075, Average Regression Loss 4.9508, Average Classification Loss: 81.5567
2020-05-03 13:09:13,769 - root - INFO - Epoch: 3, Step: 4500, Average Loss: 83.1637, Average Regression Loss 4.8952, Average Classification Loss: 78.2685
2020-05-03 13:11:12,573 - root - INFO - Epoch: 3, Step: 4600, Average Loss: 80.3106, Average Regression Loss 5.9309, Average Classification Loss: 74.3797
2020-05-03 13:13:16,327 - root - INFO - Epoch: 3, Step: 4700, Average Loss: 84.1901, Average Regression Loss 5.8308, Average Classification Loss: 78.3593
2020-05-03 13:15:19,152 - root - INFO - Epoch: 3, Step: 4800, Average Loss: 90.6957, Average Regression Loss 5.5974, Average Classification Loss: 85.0983
2020-05-03 13:17:23,692 - root - INFO - Epoch: 3, Step: 4900, Average Loss: 85.6275, Average Regression Loss 5.9760, Average Classification Loss: 79.6515
2020-05-03 13:19:29,070 - root - INFO - Epoch: 3, Step: 5000, Average Loss: 90.0485, Average Regression Loss 5.3537, Average Classification Loss: 84.6947
2020-05-03 13:21:34,676 - root - INFO - Epoch: 3, Step: 5100, Average Loss: 81.7478, Average Regression Loss 4.8799, Average Classification Loss: 76.8679
2020-05-03 13:23:40,925 - root - INFO - Epoch: 3, Step: 5200, Average Loss: 85.6153, Average Regression Loss 5.1985, Average Classification Loss: 80.4168
2020-05-03 13:25:47,509 - root - INFO - Epoch: 3, Step: 5300, Average Loss: 85.0835, Average Regression Loss 4.8620, Average Classification Loss: 80.2215
2020-05-03 13:27:52,031 - root - INFO - Epoch: 3, Step: 5400, Average Loss: 86.7485, Average Regression Loss 4.8826, Average Classification Loss: 81.8658
2020-05-03 13:29:55,852 - root - INFO - Epoch: 3, Step: 5500, Average Loss: 81.7839, Average Regression Loss 4.8529, Average Classification Loss: 76.9309
2020-05-03 13:32:00,275 - root - INFO - Epoch: 3, Step: 5600, Average Loss: 84.1348, Average Regression Loss 4.9066, Average Classification Loss: 79.2282
2020-05-03 13:34:05,996 - root - INFO - Epoch: 3, Step: 5700, Average Loss: 92.9398, Average Regression Loss 5.5449, Average Classification Loss: 87.3949
2020-05-03 13:36:12,125 - root - INFO - Epoch: 3, Step: 5800, Average Loss: 94.8767, Average Regression Loss 6.5667, Average Classification Loss: 88.3099
2020-05-03 13:38:15,012 - root - INFO - Epoch: 3, Step: 5900, Average Loss: 88.1715, Average Regression Loss 5.7519, Average Classification Loss: 82.4196
2020-05-03 13:40:21,552 - root - INFO - Epoch: 3, Step: 6000, Average Loss: 88.9116, Average Regression Loss 5.3300, Average Classification Loss: 83.5816
2020-05-03 13:42:28,890 - root - INFO - Epoch: 3, Step: 6100, Average Loss: 86.9767, Average Regression Loss 4.8745, Average Classification Loss: 82.1022
2020-05-03 13:44:31,817 - root - INFO - Epoch: 3, Step: 6200, Average Loss: 85.7754, Average Regression Loss 4.7070, Average Classification Loss: 81.0683
2020-05-03 13:46:35,455 - root - INFO - Epoch: 3, Step: 6300, Average Loss: 84.2535, Average Regression Loss 4.8667, Average Classification Loss: 79.3869
2020-05-03 13:48:41,689 - root - INFO - Epoch: 3, Step: 6400, Average Loss: 86.7559, Average Regression Loss 5.5262, Average Classification Loss: 81.2296
2020-05-03 13:50:42,932 - root - INFO - Epoch: 3, Step: 6500, Average Loss: 93.4287, Average Regression Loss 4.5814, Average Classification Loss: 88.8473
2020-05-03 13:52:51,439 - root - INFO - Epoch: 3, Step: 6600, Average Loss: 104.5236, Average Regression Loss 4.4666, Average Classification Loss: 100.0570
2020-05-03 13:54:59,314 - root - INFO - Epoch: 3, Step: 6700, Average Loss: 91.4586, Average Regression Loss 4.9607, Average Classification Loss: 86.4979
2020-05-03 13:57:06,372 - root - INFO - Epoch: 3, Step: 6800, Average Loss: 97.0521, Average Regression Loss 5.4969, Average Classification Loss: 91.5552
2020-05-03 13:59:13,673 - root - INFO - Epoch: 3, Step: 6900, Average Loss: 90.1586, Average Regression Loss 5.7924, Average Classification Loss: 84.3661
2020-05-03 14:01:17,155 - root - INFO - Epoch: 3, Step: 7000, Average Loss: 91.6732, Average Regression Loss 5.4390, Average Classification Loss: 86.2342
2020-05-03 14:03:27,495 - root - INFO - Epoch: 3, Step: 7100, Average Loss: 97.2293, Average Regression Loss 5.5190, Average Classification Loss: 91.7103
2020-05-03 14:05:32,566 - root - INFO - Epoch: 3, Step: 7200, Average Loss: 98.9344, Average Regression Loss 5.2425, Average Classification Loss: 93.6919
2020-05-03 14:07:39,152 - root - INFO - Epoch: 3, Step: 7300, Average Loss: 100.4623, Average Regression Loss 6.1659, Average Classification Loss: 94.2964
2020-05-03 14:09:44,929 - root - INFO - Epoch: 3, Step: 7400, Average Loss: 89.0787, Average Regression Loss 4.9285, Average Classification Loss: 84.1502
2020-05-03 14:11:49,314 - root - INFO - Epoch: 3, Step: 7500, Average Loss: 83.4251, Average Regression Loss 4.9778, Average Classification Loss: 78.4473
2020-05-03 14:13:59,542 - root - INFO - Epoch: 3, Step: 7600, Average Loss: 89.6267, Average Regression Loss 5.2267, Average Classification Loss: 84.4000
2020-05-03 14:16:08,160 - root - INFO - Epoch: 3, Step: 7700, Average Loss: 93.2049, Average Regression Loss 4.9349, Average Classification Loss: 88.2700
2020-05-03 14:18:12,856 - root - INFO - Epoch: 3, Step: 7800, Average Loss: 99.0856, Average Regression Loss 4.6781, Average Classification Loss: 94.4075
2020-05-03 14:20:19,542 - root - INFO - Epoch: 3, Step: 7900, Average Loss: 88.4927, Average Regression Loss 4.8277, Average Classification Loss: 83.6650
2020-05-03 14:22:26,330 - root - INFO - Epoch: 3, Step: 8000, Average Loss: 82.2623, Average Regression Loss 4.6266, Average Classification Loss: 77.6357
2020-05-03 14:24:32,709 - root - INFO - Epoch: 3, Step: 8100, Average Loss: 94.0442, Average Regression Loss 5.3529, Average Classification Loss: 88.6913
2020-05-03 14:26:37,907 - root - INFO - Epoch: 3, Step: 8200, Average Loss: 102.2493, Average Regression Loss 7.9468, Average Classification Loss: 94.3025
2020-05-03 14:28:43,606 - root - INFO - Epoch: 3, Step: 8300, Average Loss: 92.7562, Average Regression Loss 6.4568, Average Classification Loss: 86.2995
2020-05-03 14:30:51,363 - root - INFO - Epoch: 3, Step: 8400, Average Loss: 97.1984, Average Regression Loss 6.7413, Average Classification Loss: 90.4571
2020-05-03 14:32:56,104 - root - INFO - Epoch: 3, Step: 8500, Average Loss: 86.3401, Average Regression Loss 4.7897, Average Classification Loss: 81.5504
2020-05-03 14:35:03,782 - root - INFO - Epoch: 3, Step: 8600, Average Loss: 86.3555, Average Regression Loss 4.7870, Average Classification Loss: 81.5685
2020-05-03 14:37:08,790 - root - INFO - Epoch: 3, Step: 8700, Average Loss: 92.7141, Average Regression Loss 4.7775, Average Classification Loss: 87.9366
2020-05-03 14:39:14,411 - root - INFO - Epoch: 3, Step: 8800, Average Loss: 86.1814, Average Regression Loss 5.1070, Average Classification Loss: 81.0744
2020-05-03 14:41:20,372 - root - INFO - Epoch: 3, Step: 8900, Average Loss: 76.9171, Average Regression Loss 4.6325, Average Classification Loss: 72.2846
2020-05-03 14:43:28,436 - root - INFO - Epoch: 3, Step: 9000, Average Loss: 82.3972, Average Regression Loss 4.7162, Average Classification Loss: 77.6810
2020-05-03 14:46:36,941 - root - INFO - Epoch: 4, Step: 100, Average Loss: 86.2827, Average Regression Loss 5.3526, Average Classification Loss: 80.9301
2020-05-03 14:48:42,453 - root - INFO - Epoch: 4, Step: 200, Average Loss: 88.8824, Average Regression Loss 5.7959, Average Classification Loss: 83.0865
2020-05-03 14:50:47,398 - root - INFO - Epoch: 4, Step: 300, Average Loss: 87.8033, Average Regression Loss 5.1889, Average Classification Loss: 82.6144
2020-05-03 14:52:51,893 - root - INFO - Epoch: 4, Step: 400, Average Loss: 87.7970, Average Regression Loss 5.1632, Average Classification Loss: 82.6338
2020-05-03 14:54:57,514 - root - INFO - Epoch: 4, Step: 500, Average Loss: 97.3440, Average Regression Loss 4.7799, Average Classification Loss: 92.5642
2020-05-03 14:57:05,634 - root - INFO - Epoch: 4, Step: 600, Average Loss: 106.6754, Average Regression Loss 5.3233, Average Classification Loss: 101.3521
2020-05-03 14:59:13,047 - root - INFO - Epoch: 4, Step: 700, Average Loss: 92.8067, Average Regression Loss 4.7661, Average Classification Loss: 88.0406
2020-05-03 15:01:18,537 - root - INFO - Epoch: 4, Step: 800, Average Loss: 83.9821, Average Regression Loss 4.5427, Average Classification Loss: 79.4394
2020-05-03 15:03:25,029 - root - INFO - Epoch: 4, Step: 900, Average Loss: 93.9091, Average Regression Loss 5.4558, Average Classification Loss: 88.4533
2020-05-03 15:05:29,751 - root - INFO - Epoch: 4, Step: 1000, Average Loss: 86.7155, Average Regression Loss 4.7698, Average Classification Loss: 81.9458
2020-05-03 15:07:35,649 - root - INFO - Epoch: 4, Step: 1100, Average Loss: 100.4037, Average Regression Loss 5.3341, Average Classification Loss: 95.0696
2020-05-03 15:09:40,948 - root - INFO - Epoch: 4, Step: 1200, Average Loss: 89.2151, Average Regression Loss 5.4429, Average Classification Loss: 83.7721
2020-05-03 15:11:47,083 - root - INFO - Epoch: 4, Step: 1300, Average Loss: 87.1917, Average Regression Loss 5.9795, Average Classification Loss: 81.2122
2020-05-03 15:13:54,170 - root - INFO - Epoch: 4, Step: 1400, Average Loss: 93.7340, Average Regression Loss 7.2300, Average Classification Loss: 86.5040
2020-05-03 15:16:00,298 - root - INFO - Epoch: 4, Step: 1500, Average Loss: 104.1338, Average Regression Loss 6.4641, Average Classification Loss: 97.6697
2020-05-03 15:18:06,280 - root - INFO - Epoch: 4, Step: 1600, Average Loss: 93.2636, Average Regression Loss 5.5515, Average Classification Loss: 87.7120
2020-05-03 15:20:10,527 - root - INFO - Epoch: 4, Step: 1700, Average Loss: 92.6015, Average Regression Loss 5.4806, Average Classification Loss: 87.1209
2020-05-03 15:22:13,920 - root - INFO - Epoch: 4, Step: 1800, Average Loss: 88.6159, Average Regression Loss 5.1980, Average Classification Loss: 83.4179
2020-05-03 15:24:16,989 - root - INFO - Epoch: 4, Step: 1900, Average Loss: 82.9371, Average Regression Loss 5.4130, Average Classification Loss: 77.5242
2020-05-03 15:26:23,144 - root - INFO - Epoch: 4, Step: 2000, Average Loss: 99.8635, Average Regression Loss 5.3929, Average Classification Loss: 94.4707
2020-05-03 15:28:29,937 - root - INFO - Epoch: 4, Step: 2100, Average Loss: 87.6739, Average Regression Loss 5.5205, Average Classification Loss: 82.1534
2020-05-03 15:30:35,793 - root - INFO - Epoch: 4, Step: 2200, Average Loss: 89.1072, Average Regression Loss 5.7205, Average Classification Loss: 83.3866
2020-05-03 15:32:42,052 - root - INFO - Epoch: 4, Step: 2300, Average Loss: 80.6420, Average Regression Loss 5.5220, Average Classification Loss: 75.1200
2020-05-03 15:34:45,022 - root - INFO - Epoch: 4, Step: 2400, Average Loss: 93.5904, Average Regression Loss 5.2013, Average Classification Loss: 88.3891
2020-05-03 15:36:48,712 - root - INFO - Epoch: 4, Step: 2500, Average Loss: 93.0773, Average Regression Loss 6.4141, Average Classification Loss: 86.6632
2020-05-03 15:38:53,761 - root - INFO - Epoch: 4, Step: 2600, Average Loss: 90.4193, Average Regression Loss 5.4449, Average Classification Loss: 84.9744
2020-05-03 15:40:58,231 - root - INFO - Epoch: 4, Step: 2700, Average Loss: 82.1577, Average Regression Loss 5.0274, Average Classification Loss: 77.1304
2020-05-03 15:42:58,773 - root - INFO - Epoch: 4, Step: 2800, Average Loss: 86.1669, Average Regression Loss 5.0058, Average Classification Loss: 81.1611
2020-05-03 15:45:04,442 - root - INFO - Epoch: 4, Step: 2900, Average Loss: 89.1621, Average Regression Loss 5.0214, Average Classification Loss: 84.1406
2020-05-03 15:47:09,255 - root - INFO - Epoch: 4, Step: 3000, Average Loss: 87.5604, Average Regression Loss 4.8061, Average Classification Loss: 82.7543
2020-05-03 15:49:12,698 - root - INFO - Epoch: 4, Step: 3100, Average Loss: 82.0945, Average Regression Loss 5.0007, Average Classification Loss: 77.0937
2020-05-03 15:51:15,684 - root - INFO - Epoch: 4, Step: 3200, Average Loss: 86.2530, Average Regression Loss 5.2528, Average Classification Loss: 81.0002
2020-05-03 15:53:22,039 - root - INFO - Epoch: 4, Step: 3300, Average Loss: 85.5065, Average Regression Loss 4.7075, Average Classification Loss: 80.7990
2020-05-03 15:55:29,996 - root - INFO - Epoch: 4, Step: 3400, Average Loss: 87.5259, Average Regression Loss 5.6885, Average Classification Loss: 81.8374
2020-05-03 15:57:35,070 - root - INFO - Epoch: 4, Step: 3500, Average Loss: 100.6286, Average Regression Loss 7.6056, Average Classification Loss: 93.0230
2020-05-03 15:59:41,256 - root - INFO - Epoch: 4, Step: 3600, Average Loss: 83.9664, Average Regression Loss 5.7454, Average Classification Loss: 78.2210
2020-05-03 16:01:45,464 - root - INFO - Epoch: 4, Step: 3700, Average Loss: 81.8588, Average Regression Loss 5.3804, Average Classification Loss: 76.4784
2020-05-03 16:03:49,477 - root - INFO - Epoch: 4, Step: 3800, Average Loss: 86.3394, Average Regression Loss 4.9292, Average Classification Loss: 81.4102
2020-05-03 16:05:56,476 - root - INFO - Epoch: 4, Step: 3900, Average Loss: 80.7437, Average Regression Loss 4.7959, Average Classification Loss: 75.9479
2020-05-03 16:07:59,296 - root - INFO - Epoch: 4, Step: 4000, Average Loss: 80.1489, Average Regression Loss 4.7214, Average Classification Loss: 75.4275
2020-05-03 16:10:04,859 - root - INFO - Epoch: 4, Step: 4100, Average Loss: 77.4189, Average Regression Loss 5.1948, Average Classification Loss: 72.2241
2020-05-03 16:12:09,957 - root - INFO - Epoch: 4, Step: 4200, Average Loss: 90.6260, Average Regression Loss 5.5808, Average Classification Loss: 85.0452
2020-05-03 16:14:14,617 - root - INFO - Epoch: 4, Step: 4300, Average Loss: 97.2720, Average Regression Loss 5.3344, Average Classification Loss: 91.9376
2020-05-03 16:16:20,098 - root - INFO - Epoch: 4, Step: 4400, Average Loss: 87.0043, Average Regression Loss 5.1345, Average Classification Loss: 81.8698
2020-05-03 16:18:26,074 - root - INFO - Epoch: 4, Step: 4500, Average Loss: 82.0622, Average Regression Loss 5.4099, Average Classification Loss: 76.6523
2020-05-03 16:20:27,158 - root - INFO - Epoch: 4, Step: 4600, Average Loss: 89.7212, Average Regression Loss 5.4865, Average Classification Loss: 84.2347
2020-05-03 16:22:31,610 - root - INFO - Epoch: 4, Step: 4700, Average Loss: 91.3420, Average Regression Loss 5.2602, Average Classification Loss: 86.0818
2020-05-03 16:24:34,409 - root - INFO - Epoch: 4, Step: 4800, Average Loss: 94.4018, Average Regression Loss 6.4805, Average Classification Loss: 87.9213
2020-05-03 16:26:39,303 - root - INFO - Epoch: 4, Step: 4900, Average Loss: 92.3382, Average Regression Loss 5.3826, Average Classification Loss: 86.9556
2020-05-03 16:28:41,732 - root - INFO - Epoch: 4, Step: 5000, Average Loss: 97.8414, Average Regression Loss 4.9401, Average Classification Loss: 92.9013
2020-05-03 16:30:46,589 - root - INFO - Epoch: 4, Step: 5100, Average Loss: 87.5114, Average Regression Loss 5.1986, Average Classification Loss: 82.3128
2020-05-03 16:32:53,527 - root - INFO - Epoch: 4, Step: 5200, Average Loss: 93.0285, Average Regression Loss 5.0942, Average Classification Loss: 87.9343
2020-05-03 16:34:57,889 - root - INFO - Epoch: 4, Step: 5300, Average Loss: 95.9452, Average Regression Loss 5.1288, Average Classification Loss: 90.8164
2020-05-03 16:37:04,730 - root - INFO - Epoch: 4, Step: 5400, Average Loss: 78.0407, Average Regression Loss 5.0339, Average Classification Loss: 73.0069
2020-05-03 16:39:08,528 - root - INFO - Epoch: 4, Step: 5500, Average Loss: 80.2123, Average Regression Loss 4.7942, Average Classification Loss: 75.4181
2020-05-03 16:41:19,924 - root - INFO - Epoch: 4, Step: 5600, Average Loss: 89.4673, Average Regression Loss 5.1883, Average Classification Loss: 84.2789
2020-05-03 16:43:27,327 - root - INFO - Epoch: 4, Step: 5700, Average Loss: 99.4266, Average Regression Loss 5.7101, Average Classification Loss: 93.7164
2020-05-03 16:45:35,816 - root - INFO - Epoch: 4, Step: 5800, Average Loss: 94.3197, Average Regression Loss 5.0602, Average Classification Loss: 89.2595
2020-05-03 16:47:40,894 - root - INFO - Epoch: 4, Step: 5900, Average Loss: 87.1304, Average Regression Loss 5.6236, Average Classification Loss: 81.5068
2020-05-03 16:49:46,017 - root - INFO - Epoch: 4, Step: 6000, Average Loss: 90.9183, Average Regression Loss 5.0534, Average Classification Loss: 85.8649
2020-05-03 16:51:52,961 - root - INFO - Epoch: 4, Step: 6100, Average Loss: 104.5837, Average Regression Loss 4.9100, Average Classification Loss: 99.6736
2020-05-03 16:54:01,156 - root - INFO - Epoch: 4, Step: 6200, Average Loss: 97.4467, Average Regression Loss 4.9968, Average Classification Loss: 92.4499
2020-05-03 16:56:04,045 - root - INFO - Epoch: 4, Step: 6300, Average Loss: 95.0047, Average Regression Loss 5.0163, Average Classification Loss: 89.9884
2020-05-03 16:58:11,049 - root - INFO - Epoch: 4, Step: 6400, Average Loss: 81.5178, Average Regression Loss 5.0728, Average Classification Loss: 76.4450
2020-05-03 17:00:15,445 - root - INFO - Epoch: 4, Step: 6500, Average Loss: 85.5889, Average Regression Loss 4.9888, Average Classification Loss: 80.6002
2020-05-03 17:02:20,927 - root - INFO - Epoch: 4, Step: 6600, Average Loss: 89.3179, Average Regression Loss 4.8131, Average Classification Loss: 84.5049
2020-05-03 17:04:27,476 - root - INFO - Epoch: 4, Step: 6700, Average Loss: 91.0581, Average Regression Loss 4.8080, Average Classification Loss: 86.2501
2020-05-03 17:06:33,595 - root - INFO - Epoch: 4, Step: 6800, Average Loss: 83.3876, Average Regression Loss 4.7218, Average Classification Loss: 78.6658
2020-05-03 17:08:40,821 - root - INFO - Epoch: 4, Step: 6900, Average Loss: 85.0522, Average Regression Loss 4.9985, Average Classification Loss: 80.0537
2020-05-03 17:10:46,340 - root - INFO - Epoch: 4, Step: 7000, Average Loss: 101.8535, Average Regression Loss 4.8994, Average Classification Loss: 96.9541
2020-05-03 17:12:52,012 - root - INFO - Epoch: 4, Step: 7100, Average Loss: 83.5317, Average Regression Loss 4.6157, Average Classification Loss: 78.9160
2020-05-03 17:14:56,969 - root - INFO - Epoch: 4, Step: 7200, Average Loss: 93.0092, Average Regression Loss 4.8125, Average Classification Loss: 88.1967
2020-05-03 17:17:02,211 - root - INFO - Epoch: 4, Step: 7300, Average Loss: 97.2450, Average Regression Loss 4.9463, Average Classification Loss: 92.2986
2020-05-03 17:19:08,196 - root - INFO - Epoch: 4, Step: 7400, Average Loss: 90.2461, Average Regression Loss 5.0400, Average Classification Loss: 85.2061
2020-05-03 17:21:12,927 - root - INFO - Epoch: 4, Step: 7500, Average Loss: 90.2311, Average Regression Loss 4.4821, Average Classification Loss: 85.7489
2020-05-03 17:23:20,639 - root - INFO - Epoch: 4, Step: 7600, Average Loss: 91.8591, Average Regression Loss 4.7432, Average Classification Loss: 87.1159
2020-05-03 17:25:23,400 - root - INFO - Epoch: 4, Step: 7700, Average Loss: 82.8560, Average Regression Loss 4.7518, Average Classification Loss: 78.1042
2020-05-03 17:27:30,138 - root - INFO - Epoch: 4, Step: 7800, Average Loss: 82.4456, Average Regression Loss 5.0284, Average Classification Loss: 77.4172
2020-05-03 17:29:38,218 - root - INFO - Epoch: 4, Step: 7900, Average Loss: 88.8356, Average Regression Loss 5.3402, Average Classification Loss: 83.4954
2020-05-03 17:31:45,853 - root - INFO - Epoch: 4, Step: 8000, Average Loss: 90.8715, Average Regression Loss 5.7808, Average Classification Loss: 85.0907
2020-05-03 17:33:49,746 - root - INFO - Epoch: 4, Step: 8100, Average Loss: 86.2736, Average Regression Loss 5.1480, Average Classification Loss: 81.1256
2020-05-03 17:35:56,408 - root - INFO - Epoch: 4, Step: 8200, Average Loss: 83.4335, Average Regression Loss 5.4073, Average Classification Loss: 78.0261
2020-05-03 17:38:02,500 - root - INFO - Epoch: 4, Step: 8300, Average Loss: 85.7986, Average Regression Loss 5.1146, Average Classification Loss: 80.6840
2020-05-03 17:40:06,991 - root - INFO - Epoch: 4, Step: 8400, Average Loss: 81.8901, Average Regression Loss 4.7348, Average Classification Loss: 77.1553
2020-05-03 17:42:10,572 - root - INFO - Epoch: 4, Step: 8500, Average Loss: 91.7879, Average Regression Loss 4.9112, Average Classification Loss: 86.8767
2020-05-03 17:44:15,754 - root - INFO - Epoch: 4, Step: 8600, Average Loss: 95.0305, Average Regression Loss 4.8110, Average Classification Loss: 90.2196
2020-05-03 17:46:21,466 - root - INFO - Epoch: 4, Step: 8700, Average Loss: 95.0465, Average Regression Loss 5.0436, Average Classification Loss: 90.0029
2020-05-03 17:48:30,079 - root - INFO - Epoch: 4, Step: 8800, Average Loss: 97.9422, Average Regression Loss 4.7182, Average Classification Loss: 93.2240
2020-05-03 17:50:35,325 - root - INFO - Epoch: 4, Step: 8900, Average Loss: 87.9859, Average Regression Loss 4.7182, Average Classification Loss: 83.2677
2020-05-03 17:52:43,398 - root - INFO - Epoch: 4, Step: 9000, Average Loss: 82.0763, Average Regression Loss 4.6034, Average Classification Loss: 77.4729
2020-05-03 17:54:17,206 - root - INFO - Epoch: 4, Validation Loss: 103.1712, Validation Regression Loss 6.8266, Validation Classification Loss: 96.3447
2020-05-03 17:54:17,329 - root - INFO - Saved model models/basenet/WM-1.0-Epoch-4-Loss-103.17124163719916.pth
